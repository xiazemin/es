# 索引合并

ES 如何才能让数据更快的被检索使用。一句话概括了 Lucene 的设计思路就是"开新文件"。从另一个方面看，开新文件也会给服务器带来负载压力。因为默认每 1 秒，都会有一个新文件产生，每个文件都需要有文件句柄，内存，CPU 使用等各种资源。一天有 86400 秒，设想一下，每次请求要扫描一遍 86400 个文件，这个响应性能绝对好不了！

为了解决这个问题，ES 会不断在后台运行任务，主动将这些零散的 segment 做数据归并，尽量让索引内只保有少量的，每个都比较大的，segment 文件。这个过程是有独立的线程来进行的，并不影响新 segment 的产生。

归并过程中，索引状态如图 2-7，尚未完成的较大的 segment 是被排除在检索可见范围之外的：





当归并完成，较大的这个 segment 刷到磁盘后，commit 文件做出相应变更，删除之前几个小 segment，改成新的大 segment。等检索请求都从小 segment 转到大 segment 上以后，删除没用的小 segment。这时候，索引里 segment 数量就下降了，状态如图 2-8 所示：





归并策略

分层合并策略

这是ElasticSearch默认使用的合并策略。该策略将大小相似的段放在一起合并，当然段的数量会限制在每层允许的最大数量之中。依据每层允许的段数量的最大值，可以区分出一次合并中段的数量。在索引过程中，该合并策略将会计算索引中允许存在多少个段，这个值称为预算。如果索引中段的数量大于预算值，分层合并策略会首先按照段的大小\(删除文档也会考虑在内\)降序排序。随后会找出开销最小的合并方案，合并的开销计算会优先考虑比较小的段以及删除文档较多的段。 如果合并产生的段比index.merge.policy.max\_merged\_segment属性值更大，该合并策略将减少合并段的数量，以保持新段的大小在预算之下。这意味着，如果index.merge.policy.max\_merged\_segment属性值比较低，那么索引中段的数量就会比较多，查询的性能也就会比较低。用户应该根据应该程序的数量量，来监测并调整合并策略来满足业务需求。



字节大小对数合并策略

这合并策略将创建由多个大小处于对数运算后大小在指定范围索引组成的索引。索引中存在数量较少的大段，同时也会有数量低于合并因子数\(默认是10\)的小段。读者可以想象较少的段处于同一个数量级，段的数量低于合并因子。当一个新段产生并且其大小与其它段不在一个数量级时，所有处于该数量级的段就会合并。索引中段的数量与经对数运算后新段字节大小成比例。该合并策略通常能够在使段合并开销最少的情况下将索引中段的数量保持在一个比较低的水平。



文档数量对数合并策略

该合并策略与log\_byte\_size合并策略类似，只是将以段的字节大小来计算的方式换成了文档数量。该合并策略适用于索引中文档大小差别不大或者用户希望每个段中文档的数量相近的场景。



