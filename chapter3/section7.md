## Elasticsearch 集群 {#elasticsearch-集群}

lasticsearch 是分布式的架构，可以通过新增节点的方式水平扩容，并提供一定的容错性。那么，它是怎么做到的呢? 我们一个一个概念，细细道来:

* **节点\(node\)**: 是一个独立的 Elasticsearch 运行实例。可以是一台机器上多个实例，当然更常见的选择是部署在不同的机器上。多个互通节点在一起组成了一个**集群 \(cluster\)**。不同于常见的master/slave集群架构，Elasticsearch 集群中的节点是同构的，每个节点都可以处理请求，并将自己不能处理的请求"重定向"到目标节点。

* **索引\(index\)**: 一个索引，分成了多个分片。当将文档写入一个索引时，根据id做切割，交由某个具体的分片去完成写入操作。因此越多的分片数，提供了更好的并发写入性能。分片数目在索引创建就不能更改。

* **分片\(shard\)**: 即一个 Lucene 实例，从数据库的角度来理解，可以视为一个分区\(partition\)。

* **镜像分片\(replica\)**: 分片由一个 主分片 \(primary shard\)，和可配置数目的多个镜像分片组成。

  * 顾名思义，镜像分片 的数据内容和 主分片 保持数据同步。数据写入请求在主分片被完成，并由主分片将写入数据推送\(push\)到其镜像分片去。
  * 在多节点集群里，同一分片的主分片和镜像分片被分散到了不同的节点。同一个分片里文档的查询请求，既可以在主分片所在节点完成，也可以在镜像分片节点完成。
  * 此外，当主分片所在节点失效时，会将其中一个镜像分片提升为主分片。
  * 因此，更高的分片镜像数目，提供了更好的查询效率，以及更好的容错机制。

![](https://cloud.githubusercontent.com/assets/839287/13384489/f2344cdc-ded0-11e5-8fe0-93c8f634464e.png "cluster")

如图，三个节点构成的集群。有两个索引\(A，B\)。每个索引设置为3个分片，每个分片镜像数为1:

* 由于镜像分片会在节点间充分平衡，因此，当任意一个节点失效时，都不会导致数据丢失
* 由于索引个分片均匀分布到三个节点，因此，写入时，总体上可以实现三倍每个节点的写入吞吐
* 对于每个索引的查询，都可以利用到每台节点的计算能力

## Lucene 是怎么工作的? {#lucene-是怎么工作的}

前面我们提到，Elasticsearch 是构建在 Lucene 之上的。那么，Lucene \(也就是每个分片\) 是如何实现数据的实时写入和查询的呢?

一个 Lucene 由多个 segment 构成。每个 segment 自构建索引信息。在查询的时候，先由分发到每个 segment 执行，然后将结果汇总。数据写入时，是按照 segment 来组织的。为了提高写入速度，数据先写入内存，然后在定期刷回磁盘\(commit\)。

每个 segment 数据是不可变的，因此删除的时候仅仅标记为删除，相应的数据并没有彻底清除。在写入的过程中，会定期将 segment 的数据合并，在这个合并的过程中删除的数据才真正被清理掉。这也是为什么频繁更新会对性能不好的原因。最优的情况下，每个 Lucene 只有一个 segment，从而所有查询都不需要经过再次聚合。我们也可以手动触发 segment 合并，从而提高单个 Lucene 的查询性能。

写入以及合并的示意图:

![](https://cloud.githubusercontent.com/assets/839287/13384491/f239c6b2-ded0-11e5-8f12-f51a46efb0ea.png "seg1")![](https://cloud.githubusercontent.com/assets/839287/13384492/f253488a-ded0-11e5-8865-a2be651a9ac0.png "seg2")

如果要做类比的话，我们可以将写入理解为数据库系统 Write-Ahead-Logging \(WAL\) 的过程。只不过，这里写入的数据都是不变的，因此可以在写入的时候被非常高效地索引，并直接基于这些"日志"\(即segments\)查询。

## 索引维度的切割 {#索引维度的切割}

由于每个索引是固定分片数的，为了优化查询，每个分片 \(记得是 Lucene 实例\) 索引的数据不能够无限增长。很多时候，我们的写入的是按天分的日志数据。一般的做法是，按天索引。在时间维度上利用索引进行分区，Logstash 默认为`logstash-2016-02-01，logstash-2016-02-02，...`这样按天分表。在查询的时候，可以指定多个索引查询，如`logstash-*`索引匹配。在有时间范围限定查询的时候，可以提前对于潜在索引过滤，从而减少执行查询所涉及的索引数目。这也是常见的数据库分区查询优化的一个手段。

